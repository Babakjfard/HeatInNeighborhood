bxp.tmeps
hist.temps <- ggplot(data.tidy, aes(parameter))+
geom_histogram()+facet_wrap(~parameter)
h <- ggplotly(hist.temps)
hist.temps
hist.temps <- ggplot(data.tidy, aes(parameter, value))+
geom_histogram()+facet_wrap(~parameter)
hist.temps
dim(dataset)
load("validation_test.rda")
dim(dataset)
hist.temps <- ggplot(data.tidy, aes(value))+
geom_histogram()+facet_wrap(~parameter)
h <- ggplotly(hist.temps)
h
hist.temps <- ggplot(data.tidy, aes(value))+
geom_histogram()+facet_wrap(~parameter, scales = "free_x")
h <- ggplotly(hist.temps)
h
head(dataset, 5)
# tidy the data for visualization
data.tidy <- dataset %>% gather(key = "parameter", value = "value", -c(lat, lon))
bxp.tmeps <- ggplot(data.tidy, aes(x=parameter, y=value))+
geom_boxplot()
bxp.tmeps <- ggplotly(bxp.tmeps)
bxp.tmeps
# tidy the data for visualization
data.tidy <- dataset[,1:7] %>% gather(key = "parameter", value = "value", -c(lat, lon))
bxp.tmeps <- ggplot(data.tidy, aes(x=parameter, y=value))+
geom_boxplot()
bxp.tmeps <- ggplotly(bxp.tmeps)
bxp.tmeps
hist.temps <- ggplot(data.tidy, aes(value))+
geom_histogram()+facet_wrap(~parameter, scales = "free_x")
h <- ggplotly(hist.temps)
hist.temps
bxp.tmeps
# tidy the data for visualization
data.tidy <- dataset[,1:7] %>% gather(key = "parameter", value = "value", -c(lat, lon))
bxp.tmeps <- ggplot(data.tidy, aes(x=parameter, y=value))+
geom_boxplot()+facet_wrap(~parameter, scales = "free_y")
bxp.tmeps <- ggplotly(bxp.tmeps)
bxp.tmeps
hist.temps <- ggplot(data.tidy, aes(value))+
geom_histogram()+facet_wrap(~parameter, scales = "free_x")
h <- ggplotly(hist.temps)
h
head(dataset, 5)
correlations <- cor(dataset[,-c('lat', 'lon')])
data_to_corr <- dataset[, -c('lat','lon')]
head(dataset)
data_to_corr <- dataset[, -c(2,3)]
correlations <- cor(data_to_corr)
data_to_corr
data_to_corr$Land_Cover <- as.numeric(data_to_corr$Land_Cover)
correlations <- cor(data_to_corr)
corrplot(correlations, method="circle")
library(corrplot)
corrplot(correlations, method="circle")
# 1. Prepare Problem
# a) Load libraries
library(caret)
# c) Split-out validation dataset
set.seed(7)
validationIndex <- createDataPartition(Heat_in_Neighborhood$amb_temp, p=0.8, list = FALSE)
# select 20% for validation
validation <- Heat_in_Neighborhood[-validationIndex,]
# use the remaining 80% for training
dataset <- Heat_in_Neighborhood[validationIndex,]
# Now creating the sample dataset
Heat_in_Neighborhood <- cbind((temp.daily[1,3,]/10), Stations[,c('lat', 'lon')], data.pop, data.LST,
data.day_pop, data.imprev, data.LC)
library(sp) #spatial data wrangling & analysis
library(rgdal) #spatial data wrangling
library(rgeos) #spatial data wrangling & analytics
library(tidyverse) # data wrangling
library(tidycensus)
library(tidyverse)
# ================= 1) getting node locations and constructing datasets
source("GetStationData.R")
nodes.spt <- SpatialPointsDataFrame(Stations[,c('lon','lat')],Stations)
proj4string(nodes.spt) <- CRS("+init=epsg:4326")
save(nodes.spt, Stations, file = "nodes.rda")   #Saves an sf object of nodes with a dataframe of them
save(temp.daily, file = "response_values_2017.rda") #Saves an array of daily temperature in eah node
acs_key <- Sys.getenv("CENSUS_API_KEY")
# Metadata for variables is here: https://api.census.gov/data/2016/acs/acs5/variables.html (Census Data API: Variables in /data/2016/acs/acs5/variables) or you may use load_variables() function of tidyCensus package.
# and the extracted variables:
# B01003_001E : Total, TOTAL POPULATION
chicago <- get_acs(state = "IL", county = "Cook", geography = "tract", variables = "B01003_001E", geometry = TRUE)
# st_transform(., '+proj=longlat +ellps=GRS80 +no_defs')
st_crs(chicago) <- 4326
save(chicago, file = "ACS_population.rda")
library(sp) #spatial data wrangling & analysis
library(rgdal) #spatial data wrangling
library(rgeos) #spatial data wrangling & analytics
library(tidyverse) # data wrangling
#Getting the data of nodes
load("nodes.rda")
library(tidycensus)
library(tidyverse)
library(sf)
load("ACS_population.rda")
library(mapview)
library(RColorBrewer)
# Blocks
m1 <- mapview(chicago)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1+m2
# First to remove the outlier node!
outlier.index <- which.min(nodes.spt$lon)
nodes.spt <- nodes.spt[-outlier.index,]
Stations <- Stations[-outlier.index,]
temp.daily <- temp.daily[,,-outlier.index]
# Now to eliminate BGs outside the containing box
this.area <-st_sfc(st_polygon(list(rbind(c(min(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), min(nodes.spt$lat)))))) %>% st_sf()
st_crs(this.area) <- 4326
new_chicago <- st_intersection(this.area, chicago)
st_crs(this.area) <- 4326
new_chicago <- st_intersection(this.area, chicago)
st_crs(this.area) <- 4326
new_chicago <- st_intersection(this.area, chicago)
st_crs(this.area)
st_crs(chicago)
st_crs(this.area) <- 4269
new_chicago <- st_intersection(this.area, chicago)
# Now to eliminate BGs outside the containing box
this.area <-st_sfc(st_polygon(list(rbind(c(min(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), min(nodes.spt$lat)))))) %>% st_sf()
st_crs(this.area) <- 4269
new_chicago <- st_intersection(this.area, chicago)
st_crs(this.area)
st_crs(chicago)
this.area <-st_sfc(st_polygon(list(rbind(c(min(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), min(nodes.spt$lat))))))
st_crs(this.area) <- 4269
new_chicago <- st_intersection(this.area, chicago)
st_crs(chicago)
st_crs(this.area)
# Now to eliminate BGs outside the containing box
this.area <-st_sfc(st_polygon(list(rbind(c(min(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), min(nodes.spt$lat)))))) %>% st_sf()
st_crs(this.area) <- 4269
st_crs(s2) <- "+proj=longlat +datum=NAD83 +no_defs"
st_crs(this.area) <- "+proj=longlat +datum=NAD83 +no_defs"
new_chicago <- st_intersection(this.area, chicago)
st_crs(chicago)
st_crs(this.area)
class(this.area)
class(chicago)
# Now to eliminate BGs outside the containing box
this.area <-st_sfc(st_polygon(list(rbind(c(min(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), min(nodes.spt$lat)))))) %>% st_sf()
st_crs(this.area) <- 4269
st_crs(this.area) <- "+proj=longlat +datum=NAD83 +no_defs"
new_chicago <- st_intersection(this.area, chicago)
# Now to eliminate BGs outside the containing box
this.area <-st_sfc(st_polygon(list(rbind(c(min(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), min(nodes.spt$lat)))))) %>% st_sf(relation_to_geometry = NA_character_)
st_crs(this.area) <- 4269
new_chicago <- st_intersection(this.area, chicago)
st_crs(this.area) <- 4269
st_crs(this.area) <- "+proj=longlat +datum=NAD83 +no_defs"
new_chicago <- st_intersection(this.area, chicago)
st_crs(this.area) <- st_crs(chicago)
#st_crs(this.area) <- "+proj=longlat +datum=NAD83 +no_defs"
new_chicago <- st_intersection(this.area, chicago)
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m3 <- mapview(new_chicago)
m2 + m3
source("LandSat_band6.R")
```{r, message=FALSE, warning=FALSE, results='hide'}
source("LandSat_band6.R")
mapviewOptions(mapview.maxpixels = 8e+05)
m4 <- mapview(landsat, legend=FALSE)
m4+m2+m3
# !!!Now first run the first notebook. GettingData.Rmd
# !!!!!!!!!!First round: I will choose the first 90 population values and create a vector out of it
data.pop <- new_chicago$estimate[1:90]
# ================== 3)
# Calculating Land Surface Temperature from LandSat 8 Data
# source(raster_Works)
# First round : I will get a row from month of january from temp.daily
data.LST <- temp.daily[1,5,]/10 # this is the 3rd of January from all 90 stations
# ================= 4) Daytime Population
# Here is a source showing the exact variables to use in tidycensus
# to get the data (https://www.census.gov/topics/employment/commuting/guidance/calculations/acs-tables.html)
# First round: I will get it from another part of ACS
data.day_pop <- new_chicago$estimate[200:289]
# ================= 5) Percent Impreviousness
# I have the raster file for the US in 30m resolution.
# Clip the new_chivcago out of it and then the values in each node location
data.imprev <- runif(dim(Stations)[1], min = .1, max = .95)
data.LC <- as.factor(as.character(sample(12, replace = TRUE, size = dim(Stations)[1])))
# Now creating the sample dataset
Heat_in_Neighborhood <- cbind((temp.daily[1,3,]/10), Stations[,c('lat', 'lon')], data.pop, data.LST,
data.day_pop, data.imprev, data.LC)
colnames(Heat_in_Neighborhood) <- c('amb_temp', 'lat', 'lon', 'population', 'LST', 'Day_population',
'imprev', "Land_Cover" )
save(Heat_in_Neighborhood, file = "model_dataset.rda")
# 4. Evaluate Algorithms
# a) Test options and evaluation metric
# I am going to use 10-fold cross validation as starting point
trainControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "RMSE"
# b) Spot Check Algorithms
# This is a regression problem, I am goint to use 7 algorithms as follow
# Linear Regression (LR)
set.seed(7)
fit.lm <- train(amb_temp~., data=dataset, method="lm", metric=metric,
preProc=c("center", "scale"), trControl=trainControl)
# c) Split-out validation dataset
set.seed(7)
validationIndex <- createDataPartition(Heat_in_Neighborhood$amb_temp, p=0.8, list = FALSE)
# select 20% for validation
validation <- Heat_in_Neighborhood[-validationIndex,]
# use the remaining 80% for training
dataset <- Heat_in_Neighborhood[validationIndex,]
save(validation, dataset, file = "validation_test.rda")
# 4. Evaluate Algorithms
# a) Test options and evaluation metric
# I am going to use 10-fold cross validation as starting point
load("validation_test.rda")
trainControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "RMSE"
# b) Spot Check Algorithms
# This is a regression problem, I am goint to use 7 algorithms as follow
# Linear Regression (LR)
set.seed(7)
fit.lm <- train(amb_temp~., data=dataset, method="lm", metric=metric,
preProc=c("center", "scale"), trControl=trainControl)
# GLM
set.seed(7)
fit.glm <- train(amb_temp~., data=dataset, method="glm", metric=metric,
preProc=c("center", "scale"), trControl=trainControl)
# Classification and Regression Trees (CART)
set.seed(7)
grid <- expand.grid(.cp=c(0, 0.05, 0.1))
grid
fit.cart <- train(amb.temp~., data=dataset, method="rpart", metric=metric, tuneGrid=grid,
preProc=c("center", "scale"), trControl=trainControl)
fit.cart <- train(amb_temp~., data=dataset, method="rpart", metric=metric, tuneGrid=grid,
preProc=c("center", "scale"), trControl=trainControl)
# II) Non-Linear Algorithms
# SVM
set.seed(7)
fit.svm <- train(amb_temp~., data=dataset, method="svmRadial", metric=metric,
preProc=c("center", "scale"), trControl=trainControl)
# -------------------------
save(fit.cart, fit.glm, fit.lm, fit.svm, file = "trained_models_I.rda")
# c) Compare Algorithms
results <- resamples(list(LM=fit.lm, GLM=fit.glm,SVM=fit.svm, CART=fit.cart))
save(fit.cart, fit.glm, fit.lm, fit.svm, results, file = "trained_models_I.rda")
load("trained_models_I.rda")
summary(results)
dotplot(results)
summary(results)
dotplot(results)
fit.svm
# Random Forest
set.seed(7)
fit.rf <- train(amb_temp~., data=dataset, method="rf",
metric=metric, preProc=c("BoxCox"), trControl=trainControl)
save(fit.rf, results_with_ensembles, file = "models_I_withensembles.rda")
results_with_ensembles <- resamples(list(RF=fit.rf, LM=fit.lm, GLM=fit.glm,SVM=fit.svm, CART=fit.cart))
save(fit.rf, results_with_ensembles, file = "models_I_withensembles.rda")
load("models_I_withensembles.rda")
summary(results_with_ensembles)
dotplot(results_with_ensembles)
unlink('GettingData_cache', recursive = TRUE)
load("validation_test.rda")
```{r}
summary(dataset)
library(ggplot2)
library(plotly)
library(tidyverse)
# tidy the data for visualization
data.tidy <- dataset[,1:7] %>% gather(key = "parameter", value = "value", -c(lat, lon))
bxp.tmeps <- ggplot(data.tidy, aes(x=parameter, y=value))+
geom_boxplot()+facet_wrap(~parameter, scales = "free_y")
bxp.tmeps <- ggplotly(bxp.tmeps)
bxp.tmeps
hist.temps <- ggplot(data.tidy, aes(value))+
geom_histogram()+facet_wrap(~parameter, scales = "free_x")
h <- ggplotly(hist.temps)
h
library(corrplot)
data_to_corr <- dataset[, -c(2,3)]
data_to_corr$Land_Cover <- as.numeric(data_to_corr$Land_Cover)
correlations <- cor(data_to_corr)
corrplot(correlations, method="circle")
knit2html("/Users/babak.jfard/R/HeatInNeighborhood/EDA.Rmd")
knitr::knit2html("/Users/babak.jfard/R/HeatInNeighborhood/EDA.Rmd")
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/EDA.Rmd", output_format = "html_document")
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/EDA.Rmd", output_format = "html_document")
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/Eval_Algorithms.Rmd", output_format = "html_document")
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/Eval_Algorithms.Rmd", output_format = "html_document")
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/GettingData.Rmd", output_format = "html_document")
library(sp) #spatial data wrangling & analysis
library(rgdal) #spatial data wrangling
library(rgeos) #spatial data wrangling & analytics
library(tidyverse) # data wrangling
#Getting the data of nodes
load("nodes.rda")
library(tidycensus)
library(tidyverse)
library(sf)
load("ACS_population.rda")
library(sp) #spatial data wrangling & analysis
library(rgdal) #spatial data wrangling
library(rgeos) #spatial data wrangling & analytics
library(tidyverse) # data wrangling
#Getting the data of nodes
load("nodes.rda")
library(tidycensus)
library(tidyverse)
library(sf)
load("ACS_population.rda")
library(mapview)
library(RColorBrewer)
# Blocks
m1 <- mapview(chicago)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1+m2
# First to remove the outlier node!
outlier.index <- which.min(nodes.spt$lon)
nodes.spt <- nodes.spt[-outlier.index,]
Stations <- Stations[-outlier.index,]
temp.daily <- temp.daily[,,-outlier.index]
# Now to eliminate BGs outside the containing box
this.area <-st_sfc(st_polygon(list(rbind(c(min(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), min(nodes.spt$lat)))))) %>% st_sf(relation_to_geometry = NA_character_)
st_crs(this.area) <- st_crs(chicago)
#st_crs(this.area) <- "+proj=longlat +datum=NAD83 +no_defs"
new_chicago <- st_intersection(this.area, chicago)
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m3 <- mapview(new_chicago)
m2 + m3
source("LandSat_band6.R")
mapviewOptions(mapview.maxpixels = 62343791)
m4 <- mapview(landsat, legend=FALSE)
m4 <- mapview(landsat, legend=FALSE)
mapviewOptions(mapview.maxpixels = 5e+05)
m4 <- mapview(landsat, legend=FALSE)
m4+m2+m3
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/GettingData.Rmd", output_format = "html_document")
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/GettingData.Rmd", output_format = "html_document")
source('~/.active-rstudio-document', echo=TRUE)
library(mapview)
library(RColorBrewer)
# Blocks
m1 <- mapview(chicago)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1+m2
View(chicago)
library(mapview)
library(RColorBrewer)
cols <- colorRampPalette(brewer.pal(9, "Reds"))
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "percent_moe")),
co.regions=cols(40),cex="estimate",legend=FALSE)
View(chicago)
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(40),cex="estimate",legend=FALSE)
library(mapview)
library(RColorBrewer)
cols <- colorRampPalette(brewer.pal(9, "Reds"))
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(40),cex="estimate",legend=FALSE)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1+m2
m1
library(mapview)
library(RColorBrewer)
cols <- colorRampPalette(brewer.pal(9, "Reds"))
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(100),cex="estimate",legend=FALSE)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1
library(mapview)
library(RColorBrewer)
cols <- colorRampPalette(brewer.pal(9, "Reds"))
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(10),cex="estimate",legend=FALSE)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1
library(mapview)
library(RColorBrewer)
cols <- colorRampPalette(brewer.pal(20, "Reds"))
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(10),cex="estimate",legend=FALSE)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1
library(mapview)
library(RColorBrewer)
cols <- colorRampPalette(brewer.pal(20, "Reds"))
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(40),cex="estimate",legend=FALSE)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=TRUE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1
library(mapview)
library(RColorBrewer)
cols <- colorRampPalette(brewer.pal(20, "Reds"))
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(40),cex="estimate",legend=FALSE)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=TRUE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1+m2
library(mapview)
library(RColorBrewer)
cols <- colorRampPalette(brewer.pal(20, "Reds"))
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(40),cex="estimate",legend=FALSE)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=TRUE, color="red", color.region="white" popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
library(mapview)
library(RColorBrewer)
cols <- colorRampPalette(brewer.pal(20, "Reds"))
# Blocks
m1 <- mapview(chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(40),cex="estimate",legend=FALSE)
# nodes
m2 <- mapview(nodes.spt, size=5, legend=TRUE, color="red", color.region="white", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m1+m2
# First to remove the outlier node!
outlier.index <- which.min(nodes.spt$lon)
nodes.spt <- nodes.spt[-outlier.index,]
Stations <- Stations[-outlier.index,]
temp.daily <- temp.daily[,,-outlier.index]
# Now to eliminate BGs outside the containing box
this.area <-st_sfc(st_polygon(list(rbind(c(min(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), min(nodes.spt$lat)),
c(max(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), max(nodes.spt$lat)),
c(min(nodes.spt$lon), min(nodes.spt$lat)))))) %>% st_sf(relation_to_geometry = NA_character_)
st_crs(this.area) <- st_crs(chicago)
#st_crs(this.area) <- "+proj=longlat +datum=NAD83 +no_defs"
new_chicago <- st_intersection(this.area, chicago)
m2 <- mapview(nodes.spt, size=5, legend=FALSE, color="red", popup=popupTable(nodes.spt, zcol = c("address", "node_id")))
m3 <- mapview(new_chicago, z="estimate", popup=popupTable(chicago, zcol = c("estimate", "moe")),
co.regions=cols(40),cex="estimate",legend=FALSE)
m2 + m3
source("LandSat_band6.R")
mapviewOptions(mapview.maxpixels = 5e+05)
m4 <- mapview(landsat, legend=FALSE)
m4+m2+m3
load("validation_test.rda")
head(dataset, n=10)
load("validation_test.rda")
head(dataset, n=10)
load("validation_test.rda")
head(dataset, n=10)
summary(dataset)
library(ggplot2)
library(plotly)
library(tidyverse)
# tidy the data for visualization
data.tidy <- dataset[,1:7] %>% gather(key = "parameter", value = "value", -c(lat, lon))
bxp.tmeps <- ggplot(data.tidy, aes(x=parameter, y=value))+
geom_boxplot()+facet_wrap(~parameter, scales = "free_y")
bxp.tmeps <- ggplotly(bxp.tmeps)
bxp.tmeps
hist.temps <- ggplot(data.tidy, aes(value))+
geom_histogram()+facet_wrap(~parameter, scales = "free_x")
h <- ggplotly(hist.temps)
h
library(corrplot)
data_to_corr <- dataset[, -c(2,3)]
data_to_corr$Land_Cover <- as.numeric(data_to_corr$Land_Cover)
correlations <- cor(data_to_corr)
corrplot(correlations, method="circle")
dotplot(results_with_ensembles)
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/Heat_in_the_Neighborhood.Rmd", output_format = "html_document")
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/Heat_in_the_Neighborhood.Rmd", output_format = "html_document")
rmarkdown::render("/Users/babak.jfard/R/HeatInNeighborhood/Heat_in_the_Neighborhood.Rmd", output_format = "html_document")
